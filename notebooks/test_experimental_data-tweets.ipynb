{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-31T15:55:49.906537Z",
     "start_time": "2018-01-31T15:55:49.176821Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from __future__ import division, print_function, absolute_import\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "fig_width = 12\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-31T15:55:49.927462Z",
     "start_time": "2018-01-31T15:55:49.908594Z"
    }
   },
   "outputs": [],
   "source": [
    "import bayesianchangepoint as bcp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## performing inference: application to experimental data\n",
    "\n",
    "\n",
    "get your trump data:\n",
    "\n",
    "https://github.com/bpb27/trump_tweet_data_archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-31T15:55:50.158259Z",
     "start_time": "2018-01-31T15:55:49.929956Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "import urllib.request\n",
    "import json\n",
    "\n",
    "datafile = '/tmp/trumpets.json'\n",
    "try:\n",
    "    with open(datafile, 'r') as f:\n",
    "        data = json.load(f)\n",
    "except:\n",
    "    years = [2, 3, 4, 5, 6, 7]\n",
    "    years = [6, 7]\n",
    "    data = []\n",
    "    for year in years:\n",
    "        url = urllib.request.urlopen(\"https://github.com/bpb27/trump_tweet_data_archive/blob/master/master_201{0}.json.zip?raw=true\".format(str(year)))\n",
    "        print('Downloading ', url, '...')\n",
    "        with ZipFile(BytesIO(url.read())) as my_zip_file:\n",
    "            for contained_file in my_zip_file.namelist():\n",
    "                with my_zip_file.open(contained_file) as f:\n",
    "                    data.extend(json.load(f))\n",
    "    with open(datafile, 'w') as f:\n",
    "        json.dump(data, f)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-31T15:55:50.160210Z",
     "start_time": "2018-01-31T15:55:49.142Z"
    }
   },
   "outputs": [],
   "source": [
    "!ls -ltr /tmp/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-31T15:55:50.162272Z",
     "start_time": "2018-01-31T15:55:49.148Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_tweets = len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## example tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-31T15:55:50.164425Z",
     "start_time": "2018-01-31T15:55:49.156Z"
    }
   },
   "outputs": [],
   "source": [
    "d = data[34]\n",
    "d#.keys()#['followers_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## learning to handle datetimes\n",
    "\n",
    "https://docs.python.org/3/library/datetime.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-31T15:55:50.166419Z",
     "start_time": "2018-01-31T15:55:49.160Z"
    }
   },
   "outputs": [],
   "source": [
    "datetimes = [data[i]['created_at'] for i in range(n_tweets)]\n",
    "print('|'+datetimes[0]+'|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-31T15:55:50.168501Z",
     "start_time": "2018-01-31T15:55:49.163Z"
    }
   },
   "outputs": [],
   "source": [
    "import locale\n",
    "locale.getlocale()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-31T15:55:50.171042Z",
     "start_time": "2018-01-31T15:55:49.166Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "datetimes = [datetime.strptime(data[i]['created_at'], '%a %b %d %H:%M:%S %z %Y') for i in range(n_tweets)]\n",
    "print('Timestamp=', datetimes[0].timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-31T15:55:50.173295Z",
     "start_time": "2018-01-31T15:55:49.170Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "datetimes = np.array([datetime.strptime(data[i]['created_at'], '%a %b %d %H:%M:%S %z %Y').timestamp() for i in range(n_tweets)])\n",
    "print('Timestamp=', (datetimes[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-31T15:55:50.175338Z",
     "start_time": "2018-01-31T15:55:49.173Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "datetimes = [datetime.strptime(data[i]['created_at'], '%a %b %d %H:%M:%S %z %Y') for i in range(n_tweets)]\n",
    "print('Timestamp=', datetimes[0].timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-31T15:55:50.176842Z",
     "start_time": "2018-01-31T15:55:49.177Z"
    }
   },
   "outputs": [],
   "source": [
    "fig_width = 13\n",
    "fig, ax = plt.subplots(figsize=(fig_width, fig_width/1.6180))\n",
    "ax.plot(datetimes);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that within each year, tweets are in inverse chronological order. \n",
    "Let's sort things:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-31T15:55:50.178531Z",
     "start_time": "2018-01-31T15:55:49.182Z"
    }
   },
   "outputs": [],
   "source": [
    "datetimes = np.array(datetimes)\n",
    "ind_tweets = np.argsort(datetimes)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(fig_width, fig_width/1.6180))\n",
    "ax.plot(datetimes[ind_tweets]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using https://matplotlib.org/examples/api/date_demo.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evolution of followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-31T15:55:50.180166Z",
     "start_time": "2018-01-31T15:55:49.187Z"
    }
   },
   "outputs": [],
   "source": [
    "followers = np.array([data[i]['user']['followers_count'] for i in range(n_tweets)])\n",
    "\n",
    "fig_width = 13\n",
    "fig, ax = plt.subplots(figsize=(fig_width, fig_width/1.6180))\n",
    "ax.plot(datetimes[ind_tweets], followers[ind_tweets]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-31T15:55:50.181804Z",
     "start_time": "2018-01-31T15:55:49.193Z"
    }
   },
   "outputs": [],
   "source": [
    "i= 42\n",
    "data_texts = []\n",
    "for i in range(n_tweets):\n",
    "    try:\n",
    "        data_texts.append(data[i]['full_text'].lower())\n",
    "    except KeyError:\n",
    "        data_texts.append(data[i]['text'].lower())\n",
    "\n",
    "data_texts[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-31T15:55:50.183530Z",
     "start_time": "2018-01-31T15:55:49.197Z"
    }
   },
   "outputs": [],
   "source": [
    "word = 'america'\n",
    "contains_word = np.array([(word in data_text) for data_text in data_texts])\n",
    "print(sum(contains_word), 'tweets contain the word \"', word, '\" on a total of ', n_tweets, 'tweets')\n",
    "p0 = sum(contains_word) / n_tweets\n",
    "print('That is, an average probability of p0= ', p0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## detecting change points\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-31T15:55:50.185554Z",
     "start_time": "2018-01-31T15:55:49.201Z"
    }
   },
   "outputs": [],
   "source": [
    "h=1/1500\n",
    "p0=.5\n",
    "p_bar, r, beliefs = bcp.inference(contains_word[ind_tweets], h=h, p0=p0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-31T15:55:50.187491Z",
     "start_time": "2018-01-31T15:55:49.205Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axs = bcp.plot_inference(contains_word[ind_tweets], None, p_bar, r, beliefs, mode='max', max_run_length=2500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wraping things up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-31T15:55:50.189522Z",
     "start_time": "2018-01-31T15:55:49.210Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.cbook as cbook\n",
    "years = mdates.YearLocator()   # every year\n",
    "months = mdates.MonthLocator()  # every month\n",
    "yearsFmt = mdates.DateFormatter('%Y')\n",
    "fig_width = 13\n",
    "fig, ax = plt.subplots(figsize=(fig_width, fig_width/1.6180))\n",
    "\n",
    "p_hat, r_hat = bcp.readout(p_bar, r, beliefs)#, mode='max')\n",
    "\n",
    "ax.plot(datetimes[ind_tweets], p_hat)\n",
    "#ax.plot(datetimes)\n",
    "\n",
    "\n",
    "#datemin = datetime.date(datetimes.min(), 1, 1)\n",
    "#datemax = datetime.date(datetimes.max() + 1, 1, 1)\n",
    "#ax.set_xlim(datemin, datemax)\n",
    "ax.xaxis.set_major_locator(years)\n",
    "ax.xaxis.set_major_formatter(yearsFmt)\n",
    "ax.xaxis.set_minor_locator(months)\n",
    "ax.format_xdata = mdates.DateFormatter('%Y-%m-%d')\n",
    "#ax.set_yscale('log')\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {
    "height": "135px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
