{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T10:53:31.556411Z",
     "start_time": "2018-03-06T10:53:31.108123Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from __future__ import division, print_function, absolute_import\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "fig_width = 12\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T10:53:31.594103Z",
     "start_time": "2018-03-06T10:53:31.559309Z"
    }
   },
   "outputs": [],
   "source": [
    "import bayesianchangepoint as bcp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## performing inference: application to experimental data\n",
    "\n",
    "\n",
    "get your trump data:\n",
    "\n",
    "https://github.com/bpb27/trump_tweet_data_archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T10:53:38.345477Z",
     "start_time": "2018-03-06T10:53:31.596984Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "import urllib.request\n",
    "import json\n",
    "\n",
    "datafile = 'trumpets.json'\n",
    "datafile = '/tmp/trumpets.json'\n",
    "\n",
    "try:\n",
    "    with open(datafile, 'r') as f:\n",
    "        data = json.load(f)\n",
    "except:\n",
    "    years = [2, 3, 4, 5, 6, 7]\n",
    "    years = [8] #[2, 3, 4, 5, 6, 7]\n",
    "    years = [6, 7]\n",
    "    data = []\n",
    "    arctype = 'master'\n",
    "    arctype = 'condensed'\n",
    "    for year in years:\n",
    "        url = urllib.request.urlopen(\"https://github.com/bpb27/trump_tweet_data_archive/blob/master/{arctype}_201{Y}.json.zip?raw=true\".format(arctype=arctype, Y=str(year)))\n",
    "        print('Downloading ', url, '...')\n",
    "        with ZipFile(BytesIO(url.read())) as my_zip_file:\n",
    "            for contained_file in my_zip_file.namelist():\n",
    "                with my_zip_file.open(contained_file) as f:\n",
    "                    #data.extend(json.load(f))\n",
    "                    data.extend(json.loads(f.read().decode('utf-8')))\n",
    "    with open(datafile, 'w') as f:\n",
    "        json.dump(data, f)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T10:53:38.565679Z",
     "start_time": "2018-03-06T10:53:38.348489Z"
    }
   },
   "outputs": [],
   "source": [
    "!ls -ltr /tmp/*json"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T10:53:27.172536Z",
     "start_time": "2018-03-06T10:53:26.995671Z"
    }
   },
   "source": [
    "!rm -fr /tmp/trumpets.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T10:53:38.602803Z",
     "start_time": "2018-03-06T10:53:38.569565Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_tweets = len(data)\n",
    "print('number ow tweets=', n_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## example tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T10:53:38.647943Z",
     "start_time": "2018-03-06T10:53:38.606291Z"
    }
   },
   "outputs": [],
   "source": [
    "i_sample = 42\n",
    "d = data[i_sample]\n",
    "d#.keys()#['followers_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## learning to handle datetimes\n",
    "\n",
    "https://docs.python.org/3/library/datetime.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T10:53:39.078665Z",
     "start_time": "2018-03-06T10:53:38.650710Z"
    }
   },
   "outputs": [],
   "source": [
    "followers = [data[i]['user']['followers_count'] for i in range(n_tweets)]\n",
    "plt.plot(followers);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T10:53:39.142981Z",
     "start_time": "2018-03-06T10:53:39.081667Z"
    }
   },
   "outputs": [],
   "source": [
    "data_texts = []\n",
    "for i_tweet in range(n_tweets):\n",
    "    try:\n",
    "        data_texts.append(data[i]['full_text'].lower())\n",
    "    except KeyError:\n",
    "        data_texts.append(data[i]['text'].lower())\n",
    "\n",
    "data_texts[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T10:53:39.229924Z",
     "start_time": "2018-03-06T10:53:39.149496Z"
    }
   },
   "outputs": [],
   "source": [
    "word = 'america'\n",
    "contains_word = np.array([(word in data_text) for data_text in data_texts])\n",
    "print(sum(contains_word), 'tweets contain the word \"', word, '\" on a total of ', n_tweets, 'tweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T11:02:46.177062Z",
     "start_time": "2018-03-06T11:02:46.142359Z"
    }
   },
   "outputs": [],
   "source": [
    "datetimes = [data[i]['created_at'] for i in range(n_tweets)]\n",
    "print('|'+datetimes[0]+'|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T11:02:46.216944Z",
     "start_time": "2018-03-06T11:02:46.180561Z"
    }
   },
   "outputs": [],
   "source": [
    "import locale\n",
    "locale.getlocale()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T11:02:46.399163Z",
     "start_time": "2018-03-06T11:02:46.219577Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "datetimes = [datetime.strptime(data[i]['created_at'], '%a %b %d %H:%M:%S %z %Y') for i in range(n_tweets)]\n",
    "print('Timestamp=', datetimes[0].timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T11:02:46.572229Z",
     "start_time": "2018-03-06T11:02:46.402117Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "datetimes = np.array([datetime.strptime(data[i]['created_at'], '%a %b %d %H:%M:%S %z %Y').timestamp() for i in range(n_tweets)])\n",
    "print('Timestamp=', (datetimes[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T11:02:46.746314Z",
     "start_time": "2018-03-06T11:02:46.576220Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "datetimes = [datetime.strptime(data[i]['created_at'], '%a %b %d %H:%M:%S %z %Y') for i in range(n_tweets)]\n",
    "print('Timestamp=', datetimes[0].timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T11:02:47.132502Z",
     "start_time": "2018-03-06T11:02:46.749365Z"
    }
   },
   "outputs": [],
   "source": [
    "fig_width = 13\n",
    "fig, ax = plt.subplots(figsize=(fig_width, fig_width/1.6180))\n",
    "ax.plot(datetimes);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that within each year, tweets are in inverse chronological order. \n",
    "Let's sort things:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T11:02:47.520738Z",
     "start_time": "2018-03-06T11:02:47.135102Z"
    }
   },
   "outputs": [],
   "source": [
    "datetimes = np.array(datetimes)\n",
    "ind_tweets = np.argsort(datetimes)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(fig_width, fig_width/1.6180))\n",
    "ax.plot(datetimes[ind_tweets]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using https://matplotlib.org/examples/api/date_demo.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evolution of followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T11:02:47.893271Z",
     "start_time": "2018-03-06T11:02:47.523461Z"
    }
   },
   "outputs": [],
   "source": [
    "followers = np.array([data[i]['user']['followers_count'] for i in range(n_tweets)])\n",
    "\n",
    "fig_width = 13\n",
    "fig, ax = plt.subplots(figsize=(fig_width, fig_width/1.6180))\n",
    "ax.plot(datetimes[ind_tweets], followers[ind_tweets]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T11:02:47.955545Z",
     "start_time": "2018-03-06T11:02:47.897361Z"
    }
   },
   "outputs": [],
   "source": [
    "i= 42\n",
    "data_texts = []\n",
    "for i in range(n_tweets):\n",
    "    try:\n",
    "        data_texts.append(data[i]['full_text'].lower())\n",
    "    except KeyError:\n",
    "        data_texts.append(data[i]['text'].lower())\n",
    "\n",
    "data_texts[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T11:02:48.066102Z",
     "start_time": "2018-03-06T11:02:47.964070Z"
    }
   },
   "outputs": [],
   "source": [
    "word = 'america'\n",
    "contains_word = np.array([(word in data_text) for data_text in data_texts])\n",
    "print(sum(contains_word), 'tweets contain the word \"', word, '\" on a total of ', n_tweets, 'tweets')\n",
    "p0 = sum(contains_word) / n_tweets\n",
    "print('That is, an average probability of p0= ', p0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## detecting change points\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T11:02:41.538647Z",
     "start_time": "2018-03-06T10:54:52.118206Z"
    }
   },
   "outputs": [],
   "source": [
    "h = 1/1000\n",
    "max_run_length = int(2/h)\n",
    "p0 = sum(contains_word) / n_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-03-06T10:55:00.201Z"
    }
   },
   "outputs": [],
   "source": [
    "p_bar, r, beliefs = bcp.inference(contains_word[ind_tweets], h=h, p0=p0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-03-06T10:55:00.643Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axs = bcp.plot_inference(contains_word[ind_tweets], None, p_bar, r, beliefs, mode='max', max_run_length=max_run_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wraping things up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-03-06T10:55:01.789Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.cbook as cbook\n",
    "years = mdates.YearLocator()   # every year\n",
    "months = mdates.MonthLocator()  # every month\n",
    "yearsFmt = mdates.DateFormatter('%Y')\n",
    "fig_width = 13\n",
    "fig, ax = plt.subplots(figsize=(fig_width, fig_width/1.6180))\n",
    "\n",
    "p_hat, r_hat = bcp.readout(p_bar, r, beliefs)#, mode='max')\n",
    "\n",
    "ax.plot(datetimes[ind_tweets], p_hat)\n",
    "#ax.plot(datetimes)\n",
    "\n",
    "\n",
    "#datemin = datetime.date(datetimes.min(), 1, 1)\n",
    "#datemax = datetime.date(datetimes.max() + 1, 1, 1)\n",
    "#ax.set_xlim(datemin, datemax)\n",
    "ax.xaxis.set_major_locator(years)\n",
    "ax.xaxis.set_major_formatter(yearsFmt)\n",
    "ax.xaxis.set_minor_locator(months)\n",
    "ax.format_xdata = mdates.DateFormatter('%Y-%m-%d')\n",
    "#ax.set_yscale('log')\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "nbdime-conflicts": {
   "local_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "diff": [
          {
           "key": 4,
           "op": "addrange",
           "valuelist": "4"
          },
          {
           "key": 4,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": 0,
         "op": "patch"
        }
       ],
       "key": "version",
       "op": "patch"
      }
     ],
     "key": "language_info",
     "op": "patch"
    }
   ],
   "remote_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "version",
       "op": "patch"
      }
     ],
     "key": "language_info",
     "op": "patch"
    }
   ]
  },
  "toc": {
   "nav_menu": {
    "height": "135px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
